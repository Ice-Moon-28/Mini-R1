from transformers import AutoModelForCausalLM, AutoTokenizer
from huggingface_hub import HfApi, Repository

# Hugging Face Hub repo åç§°ï¼ˆæ›¿æ¢ä¸ºä½ æƒ³è¦çš„ï¼‰
repo_name = "icemoon28/qwen2.5-3b-finetuned"

# Hugging Face Hub è®¿é—®è·¯å¾„
repo_url = f"https://huggingface.co/{repo_name}"

# ä½ çš„ checkpoint ç›®å½•
checkpoint_path = "/root/autodl-tmp/runs/checkpoint-550"

# åŠ è½½æ¨¡å‹ & tokenizer
model = AutoModelForCausalLM.from_pretrained(checkpoint_path)
tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)

# æ¨é€åˆ° Hugging Face Hub
model.push_to_hub(repo_name, max_shard_size="2GB")
tokenizer.push_to_hub(repo_name)

print(f"ğŸš€ æ¨¡å‹å·²ä¸Šä¼ è‡³ {repo_url}")